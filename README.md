## Gesture-Based Mouse Control Using Hand Movements
  The Gesture-Based Mouse Control System is an innovative project that enables users to interact with their computers through hand gestures. By utilizing computer vision and advanced machine learning algorithms, the system tracks hand movements and interprets gestures to control the mouse cursor, perform clicks, and execute other actions. This solution is particularly beneficial for individuals with physical limitations, offering an intuitive and contactless alternative to traditional input devices.

## About

  The Gesture-Based Mouse Control System is a cutting-edge application that revolutionizes human-computer interaction by eliminating the need for physical input devices like a mouse or touchpad. It leverages technologies such as OpenCV, MediaPipe, and PyAutoGUI to detect hand gestures captured via a standard camera. These gestures are interpreted as commands to move the cursor, perform left and right clicks, or execute advanced functions like drag-and-drop. Designed to enhance accessibility, this system offers an inclusive solution for individuals with mobility challenges, while also providing a futuristic, intuitive user experience for general users.








## Features
<!--List the features of the project as shown below-->
- Mouse Movement Control: Control the mouse cursor using hand gestures in real-time.
- Left-Click Gesture: Perform a left-click by pinching or using specific finger gestures.
- Right-Click Gesture: Trigger a right-click by using gestures like extending specific fingers.
- Hands-Free Interaction: No need for a physical mouse; completely touchless control.


## Requirements
<!--List the requirements of the project as shown below-->
Hardware Requirements
- Camera: A standard webcam or built-in laptop camera for capturing hand movements.
- Computer: A computer or laptop with basic specifications (at least 4GB RAM, dual-core processor).
- Stable Lighting Conditions: Adequate lighting to ensure accurate gesture detection.
- Software Requirements
- Operating System: Windows, macOS, or Linux.
- Programming Language: Python 3.8 or higher.

## System Architecture
<!--Embed the system architecture diagram as shown below-->

![Screenshot 2023-11-25 133637](https://github.com/<<yourusername>>/Hand-Gesture-Recognition-System/assets/75235455/a60c11f3-0a11-47fb-ac89-755d5f45c995)


## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 - Name of the output

![Screenshot 2023-11-25 134037](https://github.com/<<yourusername>>/Hand-Gesture-Recognition-System/assets/75235455/8c2b6b5c-5ed2-4ec4-b18e-5b6625402c16)

#### Output2 - Name of the output
![Screenshot 2023-11-25 134253](https://github.com/<<yourusername>>/Hand-Gesture-Recognition-System/assets/75235455/5e05c981-05ca-4aaa-aea2-d918dcf25cb7)

Detection Accuracy: 96.7%
Note: These metrics can be customized based on your actual performance evaluations.


## Results and Impact
<!--Give the results and impact as shown below-->
The Sign Language Detection System enhances accessibility for individuals with hearing and speech impairments, providing a valuable tool for inclusive communication. The project's integration of computer vision and deep learning showcases its potential for intuitive and interactive human-computer interaction.

This project serves as a foundation for future developments in assistive technologies and contributes to creating a more inclusive and accessible digital environment.

## Articles published / References
1. N. S. Gupta, S. K. Rout, S. Barik, R. R. Kalangi, and B. Swampa, “Enhancing Heart Disease Prediction Accuracy Through Hybrid Machine Learning Methods ”, EAI Endorsed Trans IoT, vol. 10, Mar. 2024.
2. A. A. BIN ZAINUDDIN, “Enhancing IoT Security: A Synergy of Machine Learning, Artificial Intelligence, and Blockchain”, Data Science Insights, vol. 2, no. 1, Feb. 2024.




